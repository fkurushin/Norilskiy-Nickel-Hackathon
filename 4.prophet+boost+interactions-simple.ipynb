{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/df_hack_final_processed.csv\")\n",
    "df = df.astype({'MEAS_DT': 'datetime64[ns]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_graph = {\n",
    "    \"fm1\" : [],\n",
    "    \"fm2\" : [\"Cu_1.1C\", \"Ni_1.1C\", \"Cu_1.2C\", \"Ni_1.2C\"],\n",
    "    \"fm3\" : [\"Cu_2.1C\", \"Ni_2.1C\", \"Cu_2.2C\", \"Ni_2.2C\"],\n",
    "    \"fm4\" : [\"Cu_2.1C\", \"Ni_2.1C\", \"Cu_2.2C\", \"Ni_2.2C\", \"Cu_3.1C\", \"Ni_3.1C\", \"Cu_3.2C\", \"Ni_3.2C\", \"Ni_6.1C\", \"Ni_6.2C\"],\n",
    "    \"fm5\" : [\"Ni_4.1C\", \"Ni_4.1T\"],\n",
    "    \"fm6\" : [\"Ni_5.1C\", \"Ni_5.1T\", \"Ni_5.2C\", \"Ni_5.2T\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_per_fm(df, i, j, train=True):\n",
    "    non_digit_features = [col for col in df.columns.tolist() if not re.findall(r'\\d+', col)]\n",
    "    filtered_columns_1 = [col for col in df.columns.tolist() if re.findall(f'{i}\\\\.{j}', col)]\n",
    "    filtered_columns_2 = [col for col in df.columns.tolist() if re.findall(f'_{i}$', col)]\n",
    "    add_features = []\n",
    "    if train:\n",
    "        add_features = interaction_graph[f'fm{i}']\n",
    "\n",
    "    return df[non_digit_features+filtered_columns_1+filtered_columns_2 + add_features]\n",
    "\n",
    "dfd = {f\"fm{i}.{j}\" : get_dataframe_per_fm(df, i, j) for j in range(1,3) for i in range(1,7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.read_csv(\"data/test.csv\")\n",
    "test_dataframe = test_dataframe.astype({'MEAS_DT': 'datetime64[ns]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd_test = {f\"fm{i}.{j}\" : get_dataframe_per_fm(test_dataframe, i, j, False) for j in range(1, 3) for i in range(1, 7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(train_, test_):\n",
    "    train = pd.concat([train_, test_]).drop_duplicates(subset='MEAS_DT', keep=False)\n",
    "    test = pd.merge(test_, train_, how='inner', on='MEAS_DT', suffixes=('_y', '_X'))\n",
    "    return {\n",
    "        \"train\" : train, \n",
    "        \"test\" : test\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd_tt = {k : train_test_split(df_train_fm, dfd_test[k]) for k, df_train_fm in dfd.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost and Prophet as an Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая базовая идея с предсказыванием временных рядов. Сделать ансамбль усреднив ответы двух моделей, либо понять где например работает лучше одна, а где другая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_models = {}\n",
    "prophet_models = {}\n",
    "mae_values = defaultdict()\n",
    "mape_values = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ni_1.1C_min', 'Ni_1.1C_max', 'Cu_1.1C_min', 'Cu_1.1C_max']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_prophet(train, test, output_features):\n",
    "    \"\"\"\n",
    "    самый простой способ профетом пока предиктить просто min и max\n",
    "    \"\"\"\n",
    "    # output_features = list(set([feature.replace(\"_min\", \"\").replace(\"_max\", \"\") for feature in output_features]))\n",
    "    models = {}\n",
    "    predictions = {}\n",
    "    for feature in output_features:\n",
    "        print(feature)\n",
    "        train_ = train[['MEAS_DT', feature]]\n",
    "        train_.columns = ['ds', 'y']\n",
    "        m = Prophet().fit(train_)\n",
    "        future = m.make_future_dataframe(periods=len(test), freq='H', include_history=False)\n",
    "        forecast = m.predict(future)\n",
    "        models[feature] = m\n",
    "        predictions[feature] = forecast['yhat'].values\n",
    "        # predictions[feature] = {\n",
    "        #     'yhat': forecast['yhat'].values,\n",
    "        #     'yhat_lower': forecast['yhat_lower'].values,\n",
    "        #     'yhat_upper': forecast['yhat_upper'].values\n",
    "        # }\n",
    "    return models, predictions\n",
    "\n",
    "def train_catboost(train, test, output_features):\n",
    "    models = {}\n",
    "    for output_feature in output_features:\n",
    "        features_to_train_on = train.columns.tolist()\n",
    "        features_to_train_on.remove('MEAS_DT')\n",
    "        features_to_train_on = [f for f in features_to_train_on if not \"min\" in f and \"max\" not in f]\n",
    "\n",
    "        train_pool = Pool(train[features_to_train_on], label=train[output_feature])\n",
    "        test_pool = Pool(test[features_to_train_on], label=test[output_feature + \"_X\"])\n",
    "\n",
    "        model = CatBoostRegressor(loss_function='MAE')\n",
    "        model.fit(train_pool, eval_set=test_pool, use_best_model=True, plot=False, silent=True)\n",
    "        models[output_feature] = model\n",
    "        print(f\"catboost trained {output_feature}\")\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions(prophet_predictions, catboost_models, train, test, output_features, weight_prophet=0.5):\n",
    "    ensemble_predictions = {}\n",
    "    for output_feature in output_features:\n",
    "        prophet_yhat = prophet_predictions[output_feature]\n",
    "\n",
    "        features_to_train_on = train.columns.tolist()\n",
    "        features_to_train_on.remove('MEAS_DT')\n",
    "        features_to_train_on = [f for f in features_to_train_on if not \"min\" in f and \"max\" not in f]\n",
    "        test_pool = Pool(test[features_to_train_on])\n",
    "        catboost_predictions = catboost_models[output_feature].predict(test_pool)\n",
    "\n",
    "        print(prophet_yhat.shape)\n",
    "        ensemble_predictions[output_feature] = (prophet_yhat + catboost_predictions) / 2\n",
    "    return ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ni_1.1C_min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:06:09 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    }
   ],
   "source": [
    "for floatmachine_name in dfd_tt.keys():\n",
    "    train = dfd_tt[floatmachine_name]['train']\n",
    "    test = dfd_tt[floatmachine_name]['test']\n",
    "\n",
    "    output_features = [f.replace(\"_y\", \"\") for f in test.columns.tolist() if \"_y\" in f]\n",
    "    train = train.dropna(subset=output_features)\n",
    "\n",
    "    prophet_models, prophet_predictions = train_prophet(train, test, output_features)\n",
    "\n",
    "    catboost_models = train_catboost(train, test, output_features)\n",
    "\n",
    "    ensemble_preds = ensemble_predictions(prophet_predictions, catboost_models, train, test, output_features)\n",
    "\n",
    "    for output_feature in output_features:\n",
    "        test_mae = mean_absolute_error(test[output_feature + \"_X\"], ensemble_preds[output_feature])\n",
    "        test_mape = mean_absolute_percentage_error(test[output_feature + \"_X\"], ensemble_preds[output_feature])\n",
    "        \n",
    "        mae_values[output_feature] =  test_mae\n",
    "        mape_values[output_feature] =  test_mape\n",
    "        \n",
    "        print(f\"Metrics for {floatmachine_name} : {output_feature}\")\n",
    "        print(f\"Test MAE: {round(test_mae, 4)}, Test MAPE: {round(test_mape, 4)}%\")\n",
    "        print(\"----------------------------------//----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE 0.0606\n",
      "Mean MAPE 2.5088%\n"
     ]
    }
   ],
   "source": [
    "mae_list = [v for _,v in mae_values.items()]\n",
    "mape_list = [v for _,v in mape_values.items()]\n",
    "\n",
    "print(f\"Mean MAE {round(sum(mae_list) / len(mae_list), 4)}\")\n",
    "print(f\"Mean MAPE {round(sum(mape_list) / len(mape_list), 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
